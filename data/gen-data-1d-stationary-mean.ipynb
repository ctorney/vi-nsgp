{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\nimport random\nimport math\n\nimport multiprocessing\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nfrom tqdm import tqdm\nfrom scipy import interpolate\n\nfrom scipy import interpolate\n# We'll use double precision throughout for better numerics.\ndtype = np.float64\n\ntfb = tfp.bijectors\ntfd = tfp.distributions\ntfk = tfp.math.psd_kernels\n\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\ntf.config.experimental.set_memory_growth(gpus[0], True)\n\n\nobs_error = 0.005\nrepeat = 4\n\ntf.random.set_seed(repeat)\nnp.random.seed(repeat)\n\n\ndef make_functions():\n    start = 0.\n    end = 24.0*60\n    N = 1000# 10,000 points per individual\n\n    Tlen = np.sort(np.random.uniform(start-60,end+60,size=N))\n\n    KK = tfk.ExponentiatedQuadratic(amplitude=0.5,length_scale=np.float64(60.0)).matrix(Tlen[...,None],Tlen[...,None])\n\n    I = 1e-8 * tf.eye(N, dtype=tf.float64) #NN\n    KK = KK +I \n    LL=tf.linalg.cholesky(KK)\n\n    mvn = tfd.MultivariateNormalLinearOperator(\n        loc=tf.zeros_like(Tlen[None,...]),\n        scale=tf.linalg.LinearOperatorLowerTriangular(LL))\n\n    meanl = 0\n    fun_len_vals = np.squeeze(tf.math.softplus(meanl + mvn.sample()).numpy()[0])#/tf.math.softplus(0.0).numpy()\n    func_len = interpolate.interp1d(Tlen, fun_len_vals)\n\n\n    start = 0.\n    end = 24.0*60\n    N = 1000# 10,000 points per individual\n\n    Tamp = np.sort(np.random.uniform(start-60,end+60,size=N))\n\n    KK = tfk.ExponentiatedQuadratic(length_scale=np.float64(60.0)).matrix(Tamp[...,None],Tamp[...,None])\n\n    I = 1e-8 * tf.eye(N, dtype=tf.float64) #NN\n    KK = KK +I \n    LL=tf.linalg.cholesky(KK)\n\n    mvn = tfd.MultivariateNormalLinearOperator(\n        loc=tf.zeros_like(Tamp[None,...]),\n        scale=tf.linalg.LinearOperatorLowerTriangular(LL))\n\n\n    fun_amp_vals = np.squeeze(tf.math.softplus(mvn.sample()).numpy()[0])\n\n    func_amp = interpolate.interp1d(Tamp, fun_amp_vals)\n    \n    return func_len, func_amp\n\n\ndef non_stat_matern12( X, lengthscales, stddev):\n    ''' Non-stationary Matern 12 kernel'''\n\n    Xs = tf.reduce_sum(input_tensor=tf.square(X), axis=-1, keepdims=True)#(1000,1)\n    Ls = tf.square(lengthscales)#(1,1000,1)\n\n    dist = -2 * tf.matmul(X, X, transpose_b=True)\n    dist += Xs + tf.linalg.matrix_transpose(Xs)\n    Lscale = Ls + tf.linalg.matrix_transpose(Ls)\n    dist = tf.divide(2*dist,Lscale)\n    dist = tf.sqrt(tf.maximum(dist, 1e-40))\n    prefactL = 2 * tf.matmul(lengthscales, lengthscales, transpose_b=True)\n    prefactV = tf.matmul(stddev, stddev, transpose_b=True)\n\n    return tf.multiply(prefactV,tf.multiply( tf.sqrt(tf.maximum(tf.divide(prefactL,Lscale), 1e-40)),tf.exp(-dist)))\n    \n\ndef make_ts(func_len, func_amp, start, end, N):\n\n    T = np.sort(np.random.uniform(start,end,size=N))\n    # generate random times between 0 and 24 and sort them in ascending order\n    # we record observations of different individuals at different time points     \n    L = func_len(T)\n    sigma = func_amp(T)\n\n\n    KK=non_stat_matern12(T[None,...,None],L[None,...,None],sigma[None,...,None])\n    I = obs_error**2 * tf.eye(N, dtype=tf.float64) #NN\n    KK = KK +I \n            \n    jitter=1e-4\n\n    while True:\n        try:\n            LL=tf.linalg.cholesky(KK)\n            break\n        except:\n            print('adding jitter...')\n            I = jitter * tf.eye(N, dtype=tf.float64) #NN\n            KK = KK +I \n            jitter*=10\n    \n    mvn = tfd.MultivariateNormalLinearOperator(\n        loc=tf.zeros_like(T[None,...]),\n        scale=tf.linalg.LinearOperatorLowerTriangular(LL))\n    sample = mvn.sample().numpy()[0]\n\n    return sample, T, L, sigma\n        \ndef make_repeat(repeat):\n\n    n_list = [1,8,128]\n\n    func_len, func_amp = make_functions()\n    for n_indv in n_list:\n        start = 0.\n        end = 24.0*60\n        N = 8192\n\n        Y =[]\n        T_index = []\n        L_all =[]\n        var_all=[]\n\n        for i in tqdm(range(n_indv)):\n            \n            sample, T, L, sigma = make_ts(func_len, func_amp, start, end, N)\n            # collect the data and all the parameters\n            Y.append(sample)\n            T_index.append(T)\n            L_all.append(L)\n            var_all.append(sigma)\n            \n\n        y= np.array(Y).reshape(N*n_indv,1)\n\n        T_total = np.array(T_index).reshape(N*n_indv,1)\n        len_total = np.array(L_all).reshape(N*n_indv,1)\n        var_total = np.array(var_all).reshape(N*n_indv,1)\n        dataset = pd.DataFrame({'Time':T_total.flatten(), 'observations':y.flatten(),'Lengthscale':len_total.flatten(),'Variance':var_total.flatten(),'ID':0})\n\n\n        # set the IDs according to the batches\n        nb = n_indv\n        npb = N\n\n        for j in tqdm(range(nb)):\n            dataset['ID'].iloc[j*npb:(j+1)*npb]= j\n\n        dataset.to_csv('ns_synthetic_data_indv_' + str(n_indv) + '_' + str(repeat) + '.csv')\n\n\n# simulate TS data for multiple individuals\nfor irep in range(0,repeat):\n    make_repeat(irep)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-15T12:27:10.063278Z","iopub.execute_input":"2022-08-15T12:27:10.063833Z","iopub.status.idle":"2022-08-15T12:35:08.036004Z","shell.execute_reply.started":"2022-08-15T12:27:10.063729Z","shell.execute_reply":"2022-08-15T12:35:08.034558Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}