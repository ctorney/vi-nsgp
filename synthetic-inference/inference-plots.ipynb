{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\n\nimport random\n\nimport matplotlib\nfrom matplotlib import pyplot as plt\n\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nfrom tqdm import tqdm\n\nimport pickle5 as pickle\n\nimport matplotlib.ticker as tick\n\nimport sys\nsys.path.append('..')\n\nfrom nsgp_vi import nsgpVI\n\n# We'll use double precision throughout for better numerics.\ndtype = np.float64\n\ntfb = tfp.bijectors\ntfd = tfp.distributions\ntfk = tfp.math.psd_kernels\n\nplt.style.use('ggplot') \nplt.style.use('seaborn-paper') \nplt.style.use('seaborn-whitegrid') ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:24:10.325813Z","iopub.execute_input":"2022-02-10T10:24:10.326138Z","iopub.status.idle":"2022-02-10T10:24:10.334702Z","shell.execute_reply.started":"2022-02-10T10:24:10.326099Z","shell.execute_reply":"2022-02-10T10:24:10.333771Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"        df = pd.read_csv('../data/ns_synthetic_data_indv_128_0.csv')\n        T = df['Time'].values[:,None]\n        ID = df['ID'].values\n        X = np.array(df['observations']).reshape(len(T),1)\n        true_len = np.array(df['Lengthscale']).reshape(len(T),1)\n        true_var = np.array(df['Variance']).reshape(len(T),1)\n        \n        num_training_points_ = T.shape[0]\n        num_inducing_points_ = 50\n        inducing_index_points = np.linspace(0., 60*24., num_inducing_points_, endpoint=False)[..., np.newaxis]\n        np.random.shuffle(inducing_index_points)\n        \n        BATCH_SIZE=8\n        SEG_LENGTH=1024\n        allT = []\n        allX = []\n        \n        for i in np.unique(df['ID'].values):\n            allT.append(df['Time'][df['ID'].values == i].values[...,None])\n            allX.append(df['observations'][df['ID'].values == i].values[...,None])\n\n        class segment_generator:\n            def __iter__(self):\n                # loop over individuals\n                self.i = 0\n                self.max_i = len(allT)\n                \n                # loop over segments\n                self.j = 0\n                self.max_j = num_training_points_//(self.max_i*SEG_LENGTH)\n            \n                return self\n            \n            def __next__(self):\n                \n                if self.i == self.max_i:\n                    self.i = 0\n                    self.j +=1\n                    if self.j==self.max_j:\n                        raise StopIteration\n                \n                T = allT[self.i]\n                X = allX[self.i] \n\n                TT = T[self.j*SEG_LENGTH:(self.j+1)*SEG_LENGTH]\n                XX = X[self.j*SEG_LENGTH:(self.j+1)*SEG_LENGTH]\n        \n                self.i += 1\n\n                return TT,XX\n            \n        dataset = tf.data.Dataset.from_generator(segment_generator, (tf.float64)) \n        dataset = dataset.map(lambda dd: (dd[0],dd[1]))\n        dataset = dataset.shuffle(1000)\n        dataset = dataset.batch(BATCH_SIZE)\n        \n        kernel_len_a = tfp.util.TransformedVariable(2.0, tfb.Softplus(),dtype=tf.float64, name='k_len_a',trainable=True)\n        kernel_len_l = tfp.util.TransformedVariable(30.0,tfb.Chain([tfb.Scale(np.float64(60.)),tfb.Softplus()]),dtype=tf.float64, name='k_len_l',trainable=True)\n        \n        # amplitude kernel parameters, lower levels\n        kernel_amp_a = tfp.util.TransformedVariable(2.0, tfb.Softplus(), dtype=tf.float64, name='k_amp_a',trainable=True)\n        kernel_amp_l = tfp.util.TransformedVariable(30.0,tfb.Chain([tfb.Scale(np.float64(60.)),tfb.Softplus()]), dtype=tf.float64, name='k_amp_l',trainable=True)\n        \n        #kernels on the second layer\n        kernel_len = tfk.ExponentiatedQuadratic(kernel_len_a,kernel_len_l)\n        kernel_amp = tfk.ExponentiatedQuadratic(kernel_amp_a,kernel_amp_l)\n        \n        #print(str(nrd))\n\n        vgp = nsgpVI(kernel_len,kernel_amp,n_inducing_points=num_inducing_points_,inducing_index_points=inducing_index_points,dataset=dataset,num_training_points=num_training_points_, num_sequential_samples=5,num_parallel_samples=10,init_observation_noise_variance=0.005**2)  \n        \n         ","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:24:10.338242Z","iopub.execute_input":"2022-02-10T10:24:10.338727Z","iopub.status.idle":"2022-02-10T10:24:12.720135Z","shell.execute_reply.started":"2022-02-10T10:24:10.338669Z","shell.execute_reply":"2022-02-10T10:24:12.718946Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"vgp.trainable_variables","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:24:12.721558Z","iopub.execute_input":"2022-02-10T10:24:12.721928Z","iopub.status.idle":"2022-02-10T10:24:12.963114Z","shell.execute_reply.started":"2022-02-10T10:24:12.721882Z","shell.execute_reply":"2022-02-10T10:24:12.962078Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#plot all the plots at once\nZZ = np.linspace(0,24*60,200)[:,None]\n\nfig, ax = plt.subplots(3, 2,figsize=(30,33))\n\nax00 = ax[0,0]\nax01= ax[0,1]\n\nax10 = ax[1,0]\nax11= ax[1,1]\n\nax20 = ax[2,0]\nax21= ax[2,1]\n\n#n1\n\n#load the data for n1, choose one of five\n\ndf = pd.read_csv('../data/ns_synthetic_data_indv_1_0.csv')\nT = df['Time'].values[:,None]\nID = df['ID'].values\nX = np.array(df['observations']).reshape(len(T),1)\ntrue_len = np.array(df['Lengthscale']).reshape(len(T),1)\ntrue_var = np.array(df['Variance']).reshape(len(T),1)\nnum_training_points_ = T.shape[0]\n\n\n#Load the inducing points\ninducing_index_points_ = np.load('../results/T_ind_n1_0.npy')\n\n#load the model\nvgp = nsgpVI(kernel_len,kernel_amp,n_inducing_points=num_inducing_points_,inducing_index_points=inducing_index_points_,dataset=None,num_training_points=num_training_points_, num_sequential_samples=5,num_parallel_samples=10,init_observation_noise_variance=0.005**2)  \n\n#load the parameters\n\nwith open('../results/opt_n1_0.pkl', 'rb') as f:\n    loadp = pickle.load(f)\n\nfor np_v, tf_v in zip(loadp,vgp.trainable_variables):\n    tf_v.assign(np_v)\n\n#plot for n1    \n[len_mean,amp_mean], [len_var,amp_var] = vgp.get_marginal(ZZ[None,...])\n\nlen_mean = len_mean[0,:,0].numpy()\nlen_std = len_var[:,0].numpy()**0.5\n\namp_mean = amp_mean[0,:,0].numpy()\namp_std = amp_var[:,0].numpy()**0.5\n    \n\nax00.plot(ZZ,tf.math.softplus(vgp.mean_len + len_mean),color='C1')\nax00.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 1.28*len_std),tf.math.softplus(vgp.mean_len + len_mean + 1.28*len_std),color='C1',alpha=0.25)\nax00.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 1.96*len_std),tf.math.softplus(vgp.mean_len + len_mean + 1.96*len_std),color='C1',alpha=0.25)\nax00.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 2.58*len_std),tf.math.softplus(vgp.mean_len + len_mean + 2.58*len_std),color='C1',alpha=0.25)\nax00.plot(T[:8192],true_len[:8192],'--',markersize=1,color='k',alpha=1.0)\n\nax00.set_xlabel('Time',size=30)\nax00.set_ylabel('Lengthscale',size=30)\nax00.text(-0.05,1,'A', size=40, transform=ax[0, 0].transAxes)\nax00.tick_params(axis='both', which='major', labelsize=30)\ntick_locator = tick.MaxNLocator(nbins=7)\n\n\nax01.plot(T[:8192],true_var[:8192],'--',markersize=1,color='k',alpha=1.0)\nax01.plot(ZZ,tf.math.softplus(vgp.mean_amp + amp_mean),color='C1')\nax01.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 1.28*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 1.28*amp_std),color='C1',alpha=0.25)\nax01.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 1.96*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 1.96*amp_std),color='C1',alpha=0.25)\nax01.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 2.58*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 2.58*amp_std),color='C1',alpha=0.25)\n\nax01.set_xlabel('Time',size=30)\nax01.set_ylabel('Amplitude',size=30)\nax01.text(-0.05,1,'B', size=40, transform=ax[0, 1].transAxes)\nax01.tick_params(axis='both', which='major', labelsize=30)\ntick_locator = tick.MaxNLocator(nbins=7)\n\n#n8\n\n#load the data\n\ndf = pd.read_csv('../data/ns_synthetic_data_indv_8_2.csv')\nT = df['Time'].values[:,None]\nID = df['ID'].values\nX = np.array(df['observations']).reshape(len(T),1)\ntrue_len = np.array(df['Lengthscale']).reshape(len(T),1)\ntrue_var = np.array(df['Variance']).reshape(len(T),1)\n\nnum_training_points = T.shape[0]\n\n\n#load the inducing points\ninducing_index_points = np.load('../results/T_ind_n8_2.npy')\n\n#load the model\nvgp = nsgpVI(kernel_len,kernel_amp,n_inducing_points=num_inducing_points_,inducing_index_points=inducing_index_points,dataset=None,num_training_points=num_training_points, num_sequential_samples=5,num_parallel_samples=10,init_observation_noise_variance=0.005**2)  \n\n#load the parameters\n\nwith open('../results/opt_n8_2.pkl', 'rb') as f:\n    loadp = pickle.load(f)\n\nfor np_v, tf_v in zip(loadp,vgp.trainable_variables):\n    tf_v.assign(np_v)\n\n#plot for n8\n[len_mean,amp_mean], [len_var,amp_var] = vgp.get_marginal(ZZ[None,...])\n\nlen_mean = len_mean[0,:,0].numpy()\nlen_std = len_var[:,0].numpy()**0.5\n\namp_mean = amp_mean[0,:,0].numpy()\namp_std = amp_var[:,0].numpy()**0.5\n\nax10.plot(ZZ,tf.math.softplus(vgp.mean_len + len_mean),color='C1')\nax10.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 1.28*len_std),tf.math.softplus(vgp.mean_len + len_mean + 1.28*len_std),color='C1',alpha=0.25)\nax10.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 1.96*len_std),tf.math.softplus(vgp.mean_len + len_mean + 1.96*len_std),color='C1',alpha=0.25)\nax10.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 2.58*len_std),tf.math.softplus(vgp.mean_len + len_mean + 2.58*len_std),color='C1',alpha=0.25)\nax10.plot(T[:8192],true_len[:8192],'--',markersize=1,color='k',alpha=1.0)\n\nax10.set_xlabel('Time',size=30)\nax10.set_ylabel('Lengthscale',size=30)\nax10.text(-0.07,1,'C', size=40, transform=ax[1, 0].transAxes)\nax10.tick_params(axis='both', which='major', labelsize=30)\ntick_locator = tick.MaxNLocator(nbins=7)\n\nax11.plot(T[:8192],true_var[:8192],'--',markersize=1,color='k',alpha=1.0)\nax11.plot(ZZ,tf.math.softplus(vgp.mean_amp + amp_mean),color='C1')\nax11.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 1.28*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 1.28*amp_std),color='C1',alpha=0.25)\nax11.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 1.96*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 1.96*amp_std),color='C1',alpha=0.25)\nax11.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 2.58*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 2.58*amp_std),color='C1',alpha=0.25)\n\nax11.set_xlabel('Time',size=30)\nax11.set_ylabel('Amplitude',size=30)\nax11.text(-0.05,1,'D', size=40, transform=ax[1, 1].transAxes)\nax11.tick_params(axis='both', which='major', labelsize=30)\ntick_locator = tick.MaxNLocator(nbins=7)\n\n#n128 data\n\n#load the data\n\ndf = pd.read_csv('../data/ns_synthetic_data_indv_128_3.csv')\nT = df['Time'].values[:,None]\nID = df['ID'].values\nX = np.array(df['observations']).reshape(len(T),1)\ntrue_len = np.array(df['Lengthscale']).reshape(len(T),1)\ntrue_var = np.array(df['Variance']).reshape(len(T),1)\nnum_training_points = T.shape[0]\n\n#load the inducing points\ninducing_index_points = np.load('../results/T_ind_n128_3.npy')   \n\n#load the model \nvgp = nsgpVI(kernel_len,kernel_amp,n_inducing_points=num_inducing_points_,inducing_index_points=inducing_index_points,dataset=None,num_training_points=num_training_points, num_sequential_samples=5,num_parallel_samples=10,init_observation_noise_variance=0.005**2)  \n\n#load the parameters\n\nwith open('../results/opt_n128_3.pkl', 'rb') as f:\n    loadp = pickle.load(f)    \n    \nfor np_v, tf_v in zip(loadp,vgp.trainable_variables):\n    tf_v.assign(np_v)   \n\n#plot for n128\n[len_mean,amp_mean], [len_var,amp_var] = vgp.get_marginal(ZZ[None,...])\n    \nlen_mean = len_mean[0,:,0].numpy()\nlen_std = len_var[:,0].numpy()**0.5\n\namp_mean = amp_mean[0,:,0].numpy()\namp_std = amp_var[:,0].numpy()**0.5    \n    \nax20.plot(ZZ,tf.math.softplus(vgp.mean_len + len_mean),color='C1')\nax20.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 1.28*len_std),tf.math.softplus(vgp.mean_len + len_mean + 1.28*len_std),color='C1',alpha=0.25)\nax20.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 1.96*len_std),tf.math.softplus(vgp.mean_len + len_mean + 1.96*len_std),color='C1',alpha=0.25)\nax20.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_len + len_mean - 2.58*len_std),tf.math.softplus(vgp.mean_len + len_mean + 2.58*len_std),color='C1',alpha=0.25)\nax20.plot(T[:8192],true_len[:8192],'--',markersize=1,color='k',alpha=1.0)\n\nax20.set_xlabel('Time',size=30)\nax20.set_ylabel('Lengthscale',size=30)\nax20.text(-0.07,1,'E', size=40, transform=ax[2, 0].transAxes)\nax20.tick_params(axis='both', which='major', labelsize=30)\ntick_locator = tick.MaxNLocator(nbins=7)\n\nax21.plot(T[:8192],true_var[:8192],'--',markersize=1,color='k',alpha=1.0)\nax21.plot(ZZ,tf.math.softplus(vgp.mean_amp + amp_mean),color='C1')\nax21.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 1.28*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 1.28*amp_std),color='C1',alpha=0.25)\nax21.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 1.96*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 1.96*amp_std),color='C1',alpha=0.25)\nax21.fill_between(ZZ[:,0],tf.math.softplus(vgp.mean_amp + amp_mean - 2.58*amp_std),tf.math.softplus(vgp.mean_amp + amp_mean + 2.58*amp_std),color='C1',alpha=0.25)\n\nax21.set_xlabel('Time',size=30)\nax21.set_ylabel('Amplitude',size=30)\nax21.text(-0.05,1,'F', size=40, transform=ax[2, 1].transAxes)\nax21.tick_params(axis='both', which='major', labelsize=30)\ntick_locator = tick.MaxNLocator(nbins=7)\n\nfig.tight_layout()\n\nplt.savefig(\"Sythetic_inference_vi.pdf\",dpi=600)\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-10T10:24:24.451844Z","iopub.execute_input":"2022-02-10T10:24:24.452115Z","iopub.status.idle":"2022-02-10T10:24:29.257647Z","shell.execute_reply.started":"2022-02-10T10:24:24.452075Z","shell.execute_reply":"2022-02-10T10:24:29.256809Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
